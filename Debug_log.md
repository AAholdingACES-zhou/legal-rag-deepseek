#DEBUG_LOG

è®°å½•æˆ‘ä»é›¶åŸºç¡€æ–‡ç§‘ç”Ÿï¼Œåˆ°æˆåŠŸæ­å»ºä¸€ä¸ªæ³•å¾‹é¢†åŸŸ RAG ç³»ç»Ÿçš„å…¨è¿‡ç¨‹
åŒ…å«æ‰€æœ‰è¸©å‘ã€è§£å†³æ–¹æ¡ˆã€æŠ€æœ¯çªç ´ä¸åæ€

#Debug æ—¥å¿—ï¼šä» 0 åˆ° 1 è·‘é€šä¸€ä¸ª DeepSeek Ã— LlamaIndex çš„æ³•å¾‹ RAG ç³»ç»Ÿ

æœ¬é¡¹ç›®æ˜¯æˆ‘ä½œä¸ºå•†ç§‘ç”Ÿï¼ˆç»ç®¡æ³•å…¨æ²¾äº†ï¼‰æ¢ç´¢ AI äº§å“å·¥ç¨‹çš„ç¬¬ä¸€æ¬¡å®Œæ•´å®æˆ˜ã€‚
ç›®æ ‡æ˜¯ï¼šåœ¨ æ²¡æœ‰ OpenAI Key çš„æƒ…å†µä¸‹ï¼Œç”¨ DeepSeek API + LlamaIndex è‡ªå·±æ‰‹æ“å‡ºä¸€ä¸ªå¯ä»¥â€œå¼•ç”¨æ³•æ¡ + åˆ†æ + ä½œç­”â€çš„ RAG ç³»ç»Ÿã€‚

æ•´ä¸ªè¿‡ç¨‹åŒ…å«äº†å¤±è´¥ â†’ é‡è¯• â†’ é‡æ–°è®¾è®¡ â†’ æ‰‹åŠ¨ patch æ¡†æ¶ â†’ æˆåŠŸè·‘é€šçš„å…¨è¿‡ç¨‹ã€‚
è¿™ç¯‡ Debug æ—¥å¿—æ—¢æ˜¯æŠ€æœ¯æ’é”™è®°å½•ï¼Œä¹Ÿæ˜¯ä¸€ä¸ª AI äº§å“ä» 0 åˆ° 1 çš„è¿˜åŸã€‚

# ä¸ºä»€ä¹ˆè¦åšè¿™ä¸ª RAGï¼Ÿ

è¿™ä¸ªé¡¹ç›®æœ‰ä¸‰ä¸ªç›®çš„ï¼š

ğŸ¯ å±•ç¤ºæˆ‘ç†è§£ RAGã€å‘é‡æ•°æ®åº“ã€LLM çš„èƒ½åŠ›

ğŸ¯ è¯æ˜æˆ‘èƒ½ä» 0 å®Œæˆ AI åŸå‹ï¼ˆMVPï¼‰

ğŸ¯ ä½œä¸º GitHub ä½œå“é›† & ç®€å†é¡¹ç›®

æœ€ç»ˆç‰ˆæœ¬ï¼š
DeepSeek Chatï¼ˆOpenAI-Compatible APIï¼‰ Ã— LlamaIndex Ã— BGE Embeddings çš„æ³•å¾‹é—®ç­” RAG

# ä¸ºä»€ä¹ˆä¸é€‰æ‹©å·²æœ‰çš„äº‘å¹³å°æ­å»ºï¼Ÿä¸ºä»€ä¹ˆé¿å¼€OpenAIï¼Ÿ

é¦–å…ˆä¸ºä»€ä¹ˆä¸ç”¨OpenAIçš„APIï¼šé¦–å…ˆå› ä¸ºä¸»åŒ…å¢ƒå¤–å¡ä¸€åˆ†é’±æ²¡æœ‰äº†ï¼ˆæ‚²ç—›ï¼‰ã€‚æ°é€¢å‘¨æœ«ï¼Œè½¬é’±å‘¨ä¸€æ‰èƒ½åˆ°è´¦ï¼ˆä¹Ÿä¸æƒ³æ‰¾tbå……é’±ï¼‰ï¼Œæƒ³è¦å¿«ç‚¹è·‘é€šé¡¹ç›®çš„ä¸»åŒ…é€‰æ‹©ç”¨äººæ°‘å¸å……é’±çš„DeepSeekã€‚

å…¶æ¬¡æ˜¯ï¼š

Flowiseï¼šä¸Šé¢æ‰€æœ‰embeddingséƒ½æ˜¯éœ€è¦APIçš„ï¼Œåªæœ‰æœ¬åœ°éƒ¨ç½²æ‰å¯ä»¥ç”¨å…è´¹BGEï¼Œå¯¹äºä¸ªäººç”¨æˆ·æ¥è¯´æœ¬åœ°éƒ¨ç½²å¤ªéº»çƒ¦ï¼Œé‚æ”¾å¼ƒ

Difyï¼šåé‡‘å…½ï¼Œé‚æ”¾å¼ƒï¼ˆæ–‡ä»¶ä¸€ç›´æ’é˜Ÿï¼Œæ£é¼“äº†ä¸€æ™šä¸Šæ„Ÿè§‰è¢«è€äº†ï¼Œå¤±è´¥ï¼‰

Siliconflowï¼šæ²¡æœ‰å•†ç”¨ç‰ˆæœ¬ï¼Œæ²¡æœ‰åŠæ³•å®ç°æˆ‘çš„éœ€æ±‚ï¼Œæ”¾å¼ƒ

# ä¸ºä»€ä¹ˆé€‰æ‹©æœ¬åœ°ç¯å¢ƒæ­å»ºï¼Ÿåé™„debugè¸©å‘è®°å½•

GPTæ¨èä»¥åŠçœ‹èµ·æ¥å¯è¡Œï¼Œå¼€å§‹ç¯å¢ƒæ­å»ºåˆ°æœ€åè·‘é€šå¤§çº¦ç”¨äº†3å°æ—¶ï¼Œdebugå¤šäºäº†GPT

æš‚æ—¶é¡ºåˆ©çš„è¿‡ç¨‹ï¼š

# åœ¨ PowerShell é‡Œè¿›å…¥å·¥ç¨‹ç›®å½•ï¼š

cd D:\law_rag_project # åˆ›å»ºRAGé¡¹ç›®æ–‡ä»¶å¤¹

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

python -m venv .venv

# æ¿€æ´»Windows

.\.venv\Scripts\activate

# å®‰è£…ä¾èµ–

pip install llama-index llama-index-llms-deepseek llama-index-embeddings-huggingface

# âŒ pipç‰ˆæœ¬å¾ˆæ—§ + Python ç‰ˆæœ¬ä¸å…¼å®¹ + llama-index-llms-deepseek åŒ…åæ˜¯é”™è¯¯çš„ï¼ˆå®˜æ–¹åç§°å˜äº†ï¼Œgptè‡ªå·±æä¾›é”™çš„ï¼‰

æŠ¥é”™ä¸¤æ¬¡ï¼š

<img width="1324" height="405" alt="image" src="https://github.com/user-attachments/assets/a9084731-f9bc-4ffb-b58c-0992455b7a40" />

<img width="1325" height="451" alt="image" src="https://github.com/user-attachments/assets/131bc0cf-3493-434c-926c-f90fc8a586cc" />

å‡çº§åˆ°gptæ¨èçš„ python 3.11.9 

DeepSeek é‡‡ç”¨ OpenAI æ ¼å¼ APIï¼Œæ‰€ä»¥ç”¨è¿™ä¸ªåŒ…ï¼š

llama-index-llms-openai

å‡çº§ pip å, æ€•vpnå¤ªå¡ä½¿ç”¨æ¸…åæºï¼Œ ç”¨ DeepSeek çš„ OpenAI å…¼å®¹æ¥å£æ¥è·‘ RAGï¼š

pip install "llama-index==0.11.10" llama-index-llms-openai llama-index-embeddings-openai python-dotenv -i https://pypi.tuna.tsinghua.edu.cn/simple

# å‡†å¤‡ä½ çš„æ³•å¾‹æ–‡æœ¬æ•°æ®

åœ¨ C:\law_rag_project ç›®å½•ä¸‹ï¼Œæ–°å»ºä¸€ä¸ªæ–‡ä»¶å¤¹ï¼š

mkdir data

æŠŠæ¸…æ´—å¥½çš„ã€ŠåŠ³åŠ¨åˆåŒæ³•ã€‹ txt æ–‡ä»¶æ”¾è¿›dataæ–‡ä»¶å¤¹

# èµ„æºç®¡ç†å™¨æ‰‹åŠ¨åˆ›å»º . env

é€‰æ‹©ç”¨ DeepSeek çš„çœŸå® API keyï¼Œè¿™é‡Œæˆ‘è¿˜ä¸çŸ¥é“ä¹‹åè¦å¯¹LlamaIndexè¿›è¡Œæ¬ºéª—

DEEPSEEK_API_KEY=ä½ çš„æ·±åº¦æ±‚ç´¢_API_Key_å¡«è¿™é‡Œ
OPENAI_API_KEY=ä½ çš„æ·±åº¦æ±‚ç´¢_API_Key_å¡«è¿™é‡Œ
OPENAI_BASE_URL=https://api.deepseek.com 

# æ³¨æ„åªå†™ds çš„ api ï¼› ä»¥ä¸‹è§£é‡Šæ¥è‡ªgpt

å¤§éƒ¨åˆ† Python æ¨¡å‹è°ƒç”¨åº“ï¼ˆåŒ…æ‹¬ LlamaIndex çš„ OpenAI-compatible é©±åŠ¨ï¼‰é»˜è®¤ä½¿ç”¨ï¼š

OPENAI_API_KEY
OPENAI_BASE_URL

è¿™æ˜¯ä¸ºäº†å…¼å®¹ OpenAI æ ¼å¼çš„ API ï¼Œ å…¶å®åªæœ‰ä¸€ä¸ª keyï¼Œä½†ä¸ºäº†è®©æ‰€æœ‰ä»£ç éƒ½èƒ½æ‰¾åˆ°å®ƒï¼Œå¿…é¡»å†™ä¸¤é

# æ–°å»ºPythonæ–‡ä»¶ 

rag_law_bot.py

import os
from dotenv import load_dotenv

from llama_index.core import (
    SimpleDirectoryReader,
    VectorStoreIndex,
    Settings,
)
from llama_index.llms.openai import OpenAI
from llama_index.embeddings.huggingface import HuggingFaceEmbedding

# 1. è¯» .envï¼Œæ‹¿åˆ°ä½ çš„ DeepSeek Key
load_dotenv()

DEEPSEEK_API_KEY = os.getenv("OPENAI_API_KEY")
BASE_URL = os.getenv("OPENAI_BASE_URL")

if not DEEPSEEK_API_KEY:
    raise ValueError("æ²¡æœ‰æ‰¾åˆ° OPENAI_API_KEYï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶æ˜¯å¦é…ç½®æ­£ç¡®ã€‚")

# âš ï¸ å¦‚æœåé¢ä¸‹è½½ HuggingFace æ¨¡å‹å¤ªæ…¢ï¼Œå¯ä»¥è¯•è¯•é•œåƒï¼š
# os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"

# 2. é…ç½® LLMï¼ˆç”¨ DeepSeek çš„ chat æ¥å£ï¼Œèµ° OpenAI å…¼å®¹åè®®ï¼‰
llm = OpenAI(
    model="deepseek-chat",     # ä½ åœ¨ DeepSeek æ§åˆ¶å°é‡Œçœ‹åˆ°çš„ chat æ¨¡å‹å
    api_key=DEEPSEEK_API_KEY,
    base_url=BASE_URL
)

# 3. é…ç½®å‘é‡æ¨¡å‹ï¼ˆç”¨ä¸€ä¸ªä¸­æ–‡å°æ¨¡å‹ï¼Œåšæ£€ç´¢ç”¨ï¼‰
embed_model = HuggingFaceEmbedding(
    model_name="BAAI/bge-small-zh-v1.5"   # ä¸­æ–‡å‘é‡æ¨¡å‹ï¼Œå¤Ÿç”¨åˆä¸å¤ªå¤§
)

# ç»Ÿä¸€è®¾ç½®åˆ° LlamaIndex çš„å…¨å±€ Setting
Settings.llm = llm
Settings.embed_model = embed_model

# 4. è¯»å– ./data ç›®å½•é‡Œçš„æ‰€æœ‰ txt æ–‡æ¡£
print("ğŸ“š æ­£åœ¨åŠ è½½æœ¬åœ°æ–‡æ¡£ ./data ...")
documents = SimpleDirectoryReader("./data").load_data()
print(f"å·²åŠ è½½æ–‡æ¡£æ•°é‡: {len(documents)}")

# 5. æ„å»ºå‘é‡ç´¢å¼•ï¼ˆç¬¬ä¸€æ¬¡ä¼šç¨æ…¢ä¸€ç‚¹ï¼‰
print("ğŸ§  æ­£åœ¨æ„å»ºå‘é‡ç´¢å¼•ï¼ˆVectorStoreIndexï¼‰...")
index = VectorStoreIndex.from_documents(documents)
print("âœ… ç´¢å¼•æ„å»ºå®Œæˆï¼å¯ä»¥å¼€å§‹æé—®äº†ï½")

# 6. ç”ŸæˆæŸ¥è¯¢å¼•æ“
query_engine = index.as_query_engine(
    similarity_top_k=3,   # æ£€ç´¢ TopKï¼Œå¯ä»¥ä¹‹åå†è°ƒ
)

# 7. ç®€å•çš„å‘½ä»¤è¡Œå¯¹è¯å¾ªç¯

def main():
    print("\n====== åŠ³åŠ¨æ³• RAG åŠ©æ‰‹ ======")
    print("è¾“å…¥ä½ çš„é—®é¢˜ï¼Œè¾“å…¥ q / quit é€€å‡ºã€‚\n")

    while True:
        question = input("ğŸ‘©â€âš–ï¸ ä½ é—®ï¼š").strip()
        if question.lower() in {"q", "quit", "exit"}:
            print("ğŸ‘‹ Byeï½")
            break

        if not question:
            continue

        try:
            response = query_engine.query(question)
        except Exception as e:
            print(f"âŒ è°ƒç”¨å‡ºé”™: {e}")
            continue

        print("\nã€å›ç­”ã€‘")
        print(response.response)

        # å±•ç¤ºä¸€ä¸‹å¼•ç”¨åˆ°çš„æ³•æ¡ç‰‡æ®µï¼Œæ–¹ä¾¿ä½ æ ¸å¯¹
        print("\nã€å‚è€ƒç‰‡æ®µã€‘")
        for i, sn in enumerate(response.source_nodes, start=1):
            content = sn.node.get_content().strip().replace("\n", " ")
            print(f"{i}. {content[:150]}...")
        print("\n---------------------------\n")


if __name__ == "__main__":
    main()


# âŒ LlamaIndex ä¸»åŒ…ç¼ºå°‘éƒ¨åˆ†å­æ¨¡å—ï¼Œéœ€è¦é¢å¤–å®‰è£…ä¸€ä¸ªæ‰©å±•åŒ… ï¼ˆå…¨ç¨‹gptå†™ä»£ç çš„åŸå› ï¼Œä½†æ¢æˆ‘æˆ‘æ›´ä¸ä¼šå†™ï¼‰

<img width="1332" height="275" alt="image" src="https://github.com/user-attachments/assets/c3fd27dd-fba0-4ae2-b343-30e693b96bac" />

ModuleNotFoundError: No module named 'llama_index.embeddings.huggingface'

# ä¿æŒç°åœ¨è¿™ä¸ªè™šæ‹Ÿç¯å¢ƒï¼Œæ‰§è¡Œï¼š

pip install llama-index-embeddings-huggingface -i https://pypi.tuna.tsinghua.edu.cn/simple

è£…äº†å¾ˆé•¿æ—¶é—´å¤§æ¦‚10åˆ†é’Ÿä»¥ä¸Šï¼Œå› ä¸ºllama-index-* ä¼šè¿ç»­è£…ä¸€å †ä¾èµ–åŒ…

# ç‰ˆæœ¬ä¸å…¼å®¹æŠ¥é”™ï¼Œå¯ä»¥å¿½ç•¥

<img width="1205" height="825" alt="image" src="https://github.com/user-attachments/assets/213cb297-fe60-4bb5-aec4-75595f2971f1" />

ç¿»è¯‘ï¼š

llama-index-xxx éœ€è¦ llama-index-core <0.12.0, >=0.11.0, ä½†ä½ ç°åœ¨æœ‰çš„æ˜¯ 0.14.8ï¼Œç‰ˆæœ¬ä¸å…¼å®¹

éƒ¨åˆ†å…ˆå‰å·²ç»è£…è¿‡ä¸€æ‰¹ llama-index-* åŒ…ï¼ˆç‰ˆæœ¬æ¯”è¾ƒæ—§ï¼Œè¦æ±‚ core åœ¨ 0.11.x å·¦å³ï¼‰

ä½†æ˜¯é—®é¢˜ä¸å¤§ï¼Œå®‰è£…æˆåŠŸ

Successfully installed ... llama-index-embeddings-huggingface-0.6.1 ... torch-2.9.1 transformers-4.57.3

# å¦‚æœä¹‹åçœŸçš„å› ä¸ºç‰ˆæœ¬å†²çªæŒ‚äº†æ€ä¹ˆåŠï¼Ÿ èµ¶æ—¶é—´æ²¡å¿…è¦

# 1ï¼‰å…ˆæŠŠä»¥å‰è£…çš„ llama-index ç³»åˆ—éƒ½å¸æ‰
pip uninstall -y "llama-index" "llama-index-*"

# 2ï¼‰è£…ä¸€å¥—ç›¸äº’å…¼å®¹çš„ç‰ˆæœ¬ï¼ˆç¤ºä¾‹ä¸€å¥—å¤Ÿç”¨çš„ç»„åˆï¼‰
pip install "llama-index==0.11.23" \
            "llama-index-llms-openai==0.1.16" \
            "llama-index-embeddings-huggingface==0.1.6"

# âŒ è¿è¡Œåå‡ºç°ç¬¬ä¸€ä¸ªBUG 

(.venv311) PS C:\law_rag_project> python rag_law_bot.py Traceback (most recent call last): File "C:\law_rag_project\rag_law_bot.py", line 19, in <module> raise ValueError("æ²¡æœ‰æ‰¾åˆ° OPENAI_API_KEYï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶æ˜¯å¦é…ç½®æ­£ç¡®ã€‚") ValueError: æ²¡æœ‰æ‰¾åˆ° OPENAI_API_KEYï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶æ˜¯å¦é…ç½®æ­£ç¡®ã€‚ (.venv311) PS C:\law_rag_project>

.envæ–‡ä»¶åç¼€é”™è¯¯ï¼Œæˆ‘ä¸€å¼€å§‹å†™çš„æ˜¯ env.txt

# å¼ºåˆ¶é‡å‘½å

ren env.txt .env

dir -Force

<img width="1207" height="557" alt="image" src="https://github.com/user-attachments/assets/f7216d92-2ef6-4f77-b754-74ffb90e719f" />

# âŒ è¿è¡Œåå‡ºç°ç¬¬äºŒä¸ªBUG ã€é‡è¦ã€‘

<img width="679" height="258" alt="image" src="https://github.com/user-attachments/assets/cb42f92d-8db6-4c57-a5d7-79f3046cc61c" />

LlamaIndex ä¸è®¤è¯† deepseek-chat è¿™ä¸ªâ€œOpenAI æ¨¡å‹åâ€ï¼Œåªè®¤è¯†å®˜æ–¹çš„ GPT æ¨¡å‹åï¼ˆgpt-4oã€gpt-3.5-turbo ç­‰ï¼‰

#  LlamaIndex æ‰“è¡¥ä¸ï¼Œè®©å®ƒè®¤è¯† deepseek-chat
_orig_ctx_func = openai_utils.openai_modelname_to_contextsize

def _patched_openai_modelname_to_contextsize(model_name: str) -> int:
    # å¯¹ deepseek ç³»åˆ—æ¨¡å‹ï¼Œè¿”å›ä¸€ä¸ªå›ºå®šçš„ context window
    if model_name.startswith("deepseek"):
        # DeepSeek å®˜æ–¹ä¸Šä¸‹æ–‡ä¸€èˆ¬æ˜¯ 8K æˆ– 16Kï¼Œè¿™é‡Œä¿å®ˆç»™ 8192
        return 8192
    # å…¶ä»–æ¨¡å‹ä¾ç„¶èµ°åŸæ¥çš„é€»è¾‘
    return _orig_ctx_func(model_name)

openai_utils.openai_modelname_to_contextsize = _patched_openai_modelname_to_contextsize
print("ğŸ”§ å·²ä¸º LlamaIndex æ‰“è¡¥ä¸ï¼Œä½¿å…¶æ”¯æŒ deepseek-chat æ¨¡å‹ã€‚")

# æŒç»­æŠ¥é”™

<img width="617" height="269" alt="image" src="https://github.com/user-attachments/assets/70126847-91c8-4fe9-b8e2-326bb6c78b5a" />

# è§£é‡Šï¼šLlamaIndex è¿™ä¸ªåŒ…åœ¨åˆ«çš„æ–‡ä»¶é‡Œå·²ç»æŠŠå‡½æ•°â€œæ‹·è´äº†ä¸€ä»½å¼•ç”¨â€ï¼Œæ‰€ä»¥æˆ‘ä»¬åœ¨ä»£ç é‡Œ monkey-patch äº† utils.openai_modelname_to_contextsize ä¹Ÿæ²¡æ³•è¦†ç›–é‚£ä»½æ—§å¼•ç”¨

# LlamaIndex æŠ¥ Unknown model 'deepseek-chat'ï¼Œå°±æ˜¯å› ä¸ºï¼šopenai_modelname_to_contextsize() åªè®¤è¿™ä¸ª ALL_AVAILABLE_MODELS é‡Œçš„ key

is_chat_model() åªè®¤ CHAT_MODELS é‡Œçš„ key

# æ‰¾åˆ°æŠ¥é”™æºæ–‡ä»¶ï¼ŒæŠŠ deepseek-chat æŠŠå®ƒâ€œéª—â€æˆä¸€ä¸ªå·²çŸ¥æ¨¡å‹å°±è¡Œï¼ˆå…³é”®ï¼‰

C:\law_rag_project\.venv311\Lib\site-packages\llama_index\llms\openai\utils.py

ALL_AVAILABLE_MODELS = {
    **O1_MODELS,
    **GPT4_MODELS,
    **TURBO_MODELS,
    **GPT3_5_MODELS,
    **GPT3_MODELS,
    **AZURE_TURBO_MODELS,
    "deepseek-chat": 8192,   # ğŸ‘ˆ æ–°å¢è¿™ä¸€è¡Œ
}

CHAT_MODELS = {
    **O1_MODELS,
    **GPT4_MODELS,
    **TURBO_MODELS,
    **AZURE_TURBO_MODELS,
    "deepseek-chat": 8192,   # ğŸ‘ˆ è¿™é‡Œä¹ŸåŠ ä¸€è¡Œ
}


# âŒ è¿è¡Œåå‡ºç°ç¬¬ä¸‰ä¸ªBUG ã€æœ€é‡è¦ã€‘

æŸ¥è¯¢å‡ºé”™ï¼š Error code: 401 - {'error': {'message': 'Incorrect API key provided: ************. 
You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'code': 'invalid_api_key', 'param': None}}

å¿…é¡»æ‰‹åŠ¨å‘Šè¯‰openai SDKï¼Œbase_url åˆ° deepseekï¼Œkey æ˜¯ deepseek key

# åŠ å…¥ğŸ”§ DeepSeek è¡¥ä¸

import openai

openai.api_key = os.getenv("OPENAI_API_KEY")
openai.base_url = "https://api.deepseek.com/v1"

print("OpenAI SDK å·²æ”¹ç”¨ DeepSeek API")
print("âœ… å·²è¯»å–åˆ° OPENAI_API_KEYï¼Œå‡†å¤‡åˆå§‹åŒ– LLM ä¸å‘é‡æ¨¡å‹...")

# åç»­ç¾åŒ–è¾“å‡º

<img width="1210" height="470" alt="image" src="https://github.com/user-attachments/assets/6bdf2074-6f3f-44b8-b1a9-e0b0112576a0" />

160ä¸ªå­—ç¬¦é™åˆ¶å¤ªçŸ­ï¼Œç›´æ¥æ”¹ä¸ºï¼š

def pretty_print_response(resp):
    """ç¾åŒ–è¾“å‡ºï¼šæ­£æ–‡ + å¼•ç”¨ç‰‡æ®µ"""
    print("\n====== æ¨¡å‹å›ç­” ======\n")
    print(str(resp))

    # å±•ç¤ºå¼•ç”¨çš„æ³•æ¡ç‰‡æ®µï¼Œæ–¹ä¾¿æ ¸æŸ¥
    if getattr(resp, "source_nodes", None):
        print("\n====== å¼•ç”¨ç‰‡æ®µï¼ˆTop 3ï¼‰======")
        for i, sn in enumerate(resp.source_nodes[:3], 1):
            text = sn.node.get_content().strip()
            print(f"\n[{i}] score={sn.score:.3f}\n{text}\n")





